TLA's
from nltk.book import *
FreqDist(text)
fdist = FreqDist(text)
 sorted([w for w in set(text) if len(w) == 3 and (w.upper() == w)])

APPEARS MORE THAN 7 TIMES AND HAS LENGTH GREATER THAN 7
sorted([w for w in set(text) if len(w) >7 and fdist[w] >7])

HOW LONG ARE THE WORDS

>>> fdist=FreqDist([len(w) for w in text])
>>> fdist
FreqDist({3: 3665, 1: 3610, 2: 3427, 4: 3214, 5: 1623, 7: 1054, 6: 1025, 8: 654, 9: 375, 10: 236, ...})
>>> fdist.keys()
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 44, 29]

>>> fdist.items()
[(1, 3610), (2, 3427), (3, 3665), (4, 3214), (5, 1623), (6, 1025), (7, 1054), (8, 654), (9, 375), (10, 236), (11, 136), (12, 49), (13, 38), (14, 5), (15, 6), (16, 2), (17, 1), (18, 3), (44, 1), (29, 2)]
>>> fdist.max()
3
>>> fdist[3]
3665
>>> fdist.freq(3)
0.19162396737425494

fdist = FreqDist(samples)   create a frequency distribution containing the given samples
fdist.inc(sample)   increment the count for this sample
fdist['monstrous']  count of the number of times a given sample occurred
fdist.freq('monstrous')   frequency of a given sample
fdist.N()   total number of samples
fdist.keys()  the samples sorted in order of decreasing frequency
for sample in fdist:  iterate over the samples, in order of decreasing frequency
fdist.max()   sample with the greatest count
fdist.tabulate()  tabulate the frequency distribution
fdist.plot()  graphical plot of the frequency distribution
fdist.plot(cumulative=True)   cumulative plot of the frequency distribution
fdist1 < fdist2   test if samples in fdist1 occur less frequently than in fdist2
